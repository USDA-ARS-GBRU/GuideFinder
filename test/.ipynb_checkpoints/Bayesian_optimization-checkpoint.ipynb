{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "Guidefinder enables users to design RNA targets for entire genomes using any PAM and any genome. The most computatioanlly costly step of Guidefinder compares the Hamming distance of all potenial guide RNA targets in the genome to all other targets. For a typical bacterial genome and Cas9 (Protospacer ajacent Motif site NGG) this could be a (10^6 * (10^6 -1))/2 ~ 5^11 comparisons. To avoid that number of comparisons we perform approxamate nearest neighbor search using Hierarchical Navigable Small World (HNSW) graphs in the NMSlib package.  This is much faster but it requires construction of an index and selecting index and search parameters that balance index speed, search speed, and Recall.\n",
    "\n",
    "## Bayesian optimization\n",
    "\n",
    "We need to optimize the following index parameters:\n",
    "* M (int) 10-100\n",
    "* efC (int)10-1000\n",
    "* post (int) 0-2\n",
    "\n",
    "And the search parameter:\n",
    "* ec (int) 10-2000\n",
    "\n",
    "We want to minimize search time and maximize 1-NN recall\n",
    "\n",
    "To do this we will use the Python package [GPflowOpt](https://gpflowopt.readthedocs.io/en/latest/notebooks/multiobjective.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import time \n",
    "import math\n",
    "\n",
    "from Bio import SeqIO\n",
    "import nmslib \n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import guidemaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the ground truth data\n",
    "\n",
    "Initially a gound truth dataset will be calculated using the brute force method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling ground truth\n",
    "pamobj = guidemaker.core.Pam(\"NGG\", \"5prime\")\n",
    "gb = SeqIO.parse(\"test_data/Carsonella_ruddii.fasta\", \"fasta\")\n",
    "pamtargets = pamobj.find_targets(seq_record_iter=gb, strand=\"forward\", target_len=20)\n",
    "tl = guidemaker.core.TargetList(targets=pamtargets, lcp=10, hammingdist=2, knum=2)\n",
    "tl.find_unique_near_pam()\n",
    "bintargets = tl._one_hot_encode(tl.targets)\n",
    "\n",
    "index = nmslib.init(space='bit_hamming',\n",
    "                    dtype=nmslib.DistType.INT,\n",
    "                    data_type=nmslib.DataType.OBJECT_AS_STRING,\n",
    "                    method='seq_search')\n",
    "index.addDataPointBatch(bintargets)\n",
    "index.createIndex( print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "truth_list = index.knnQueryBatch(bintargets, k=3, num_threads = 4)\n",
    "        \n",
    "end = time.time()\n",
    "\n",
    "print('brute-force kNN time total=%f (sec), per query=%f (sec)' % \n",
    "      (end-start, float(end-start)/len(bintargets)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(results, truth):\n",
    "    \"\"\"Calculate recall for top two kNN distances\n",
    "\n",
    "    calulate recall on the top 2 distances (not labels becasue we really care that the algoritm estimates the correct\n",
    "    distance not the exact value of the neighbor and there can be multiple nieghbors with the same edit distance .)\n",
    "    \"\"\"\n",
    "    dat = zip(results, truth)\n",
    "    assert len(results) ==len(truth)\n",
    "    tot = len(results)\n",
    "    correct = 0\n",
    "    for res, tr in dat:\n",
    "        if all(res[1][0:2] ==tr[1][0:2]): # it should have been 2 not 1, then need to use all to compare all the element of an array\n",
    "            correct += 1\n",
    "    return correct/tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(truth, bintargets, M, efC, post, ef, delaunay_type=2, threads=4):\n",
    "    start = time.time()\n",
    "    index_params = {'M': M, 'indexThreadQty': threads,'efConstruction': efC, 'post': post}\n",
    "    index = nmslib.init(space='bit_hamming',\n",
    "                    dtype=nmslib.DistType.INT,\n",
    "                    data_type=nmslib.DataType.OBJECT_AS_STRING,\n",
    "                    method='hnsw')\n",
    "    index.addDataPointBatch(bintargets)\n",
    "    index.createIndex(index_params)\n",
    "    index.setQueryTimeParams({'efSearch': ef})\n",
    "    results_list = index.knnQueryBatch(bintargets, k=3, num_threads = 4)\n",
    "    end = time.time()\n",
    "    rc = recall(results_list, truth)\n",
    "    return rc, float(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_func(truth=truth_list, bintargets=bintargets, M=10, efC=50, post=1, ef=200, threads=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_func(truth=truth_list, bintargets=bintargets, M=10, efC=50, post=1, ef=200, threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter optimization for NMSLIB\n",
    "https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n",
    "\n",
    "- ef_construction - controls index search speed/build speed tradeoff\n",
    "\n",
    "- M - is tightly connected with internal dimensionality of the data. Strongly affects the memory consumption (~M)\n",
    "\n",
    "- Higher M leads to higher accuracy/run_time at fixed ef/efConstruction\n",
    "\n",
    "Controlling the recall by setting ef:\n",
    "- higher ef leads to better accuracy, but slower search\n",
    "\n",
    "\n",
    "\n",
    "- ef - the size of the dynamic list for the nearest neighbors (used during the search). Higher ef leads to more accurate but slower search. ef cannot be set lower than the number of queried nearest neighbors k. The value ef of can be anything between k and the size of the dataset.\n",
    "\n",
    "\n",
    "- M - the number of bi-directional links created for every new element during construction. Reasonable range for M is 2-100. Higher M work better on datasets with high intrinsic dimensionality and/or high recall,\n",
    "  while low M work better for datasets with low intrinsic dimensionality and/or low recalls.\n",
    "  The parameter also determines the algorithm's memory consumption, which is roughly M * 8-10 bytes per stored element.As an example for dim=4 random vectors optimal M for search is somewhere around 6, while for\n",
    "  high dimensional datasets (word embeddings, good face descriptors), higher M are required (e.g. M=48-64) \n",
    "  for optimal performance at high recall. The range M=12-48 is ok for the most of the use cases.\n",
    "  When M is changed one has to update the other parameters. Nonetheless, ef and ef_construction parameters\n",
    "  can be roughly estimated by assuming that M*ef_{construction} is a constant\n",
    "\n",
    "\n",
    "- ef_construction - the parameter has the same meaning as ef, but controls the index_time/index_accuracy.\n",
    "  Bigger ef_construction leads to longer construction, but better index quality. At some point,\n",
    "  increasing ef_construction does not improve the quality of the index. One way to check if\n",
    "  the selection of ef_construction was ok is to measure a recall for M nearest neighbor\n",
    "  search when ef =ef_construction: if the recall is lower than 0.9, than there is room for improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_nsmlib_para(increase_by: int=10):\n",
    "    M_range = range(2, 101, increase_by)\n",
    "    ef_range = range(3, 257, increase_by)\n",
    "    efC_range = range(3, 257, increase_by)\n",
    "    post_range = range(1, 101, increase_by)\n",
    "    print(\"Total number of combinations: \", (len(M_range) * len(ef_range) * len(efC_range) * len(post_range)))\n",
    "    pdict = dict(run=[], M = [], ef = [], efC = [], post = [], accuracy = [], time=[])\n",
    "    n=1\n",
    "    for m in M_range:\n",
    "        for ef in ef_range:\n",
    "            for efC in efC_range:\n",
    "                for post in post_range:\n",
    "                    rc, tt = test_func(truth=truth_list, bintargets=bintargets, M=m, efC=efC, post=post, ef=ef, threads=4)\n",
    "                    n +=1\n",
    "                    if rc > 0.9900000000000000:\n",
    "                        pdict['run'].append(n)\n",
    "                        pdict['M'].append(m)\n",
    "                        pdict['ef'].append(ef)\n",
    "                        pdict['efC'].append(efC)\n",
    "                        pdict['post'].append(post)\n",
    "                        pdict['accuracy'].append(rc)\n",
    "                        pdict['time'].append(tt)\n",
    "                        print(n, m, ef, efC, post, rc, tt)\n",
    "    return pdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = sim_nsmlib_para(increase_by=50)\n",
    "\n",
    "df = pd.DataFrame.from_dict(aa)\n",
    "\n",
    "\n",
    " df.sort_values(['accuracy', 'time'], ascending=[True, False])\n",
    "\n",
    "\n",
    "\n",
    " df.sort_values(['time'], ascending=[False])\n",
    "\n",
    "\n",
    "\n",
    " df['time'].max() / df['time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sim_nsmlib_para_optimized(increase_by: int=10):\n",
    "    M = [8, 16, 24, 32]\n",
    "    ef_range = range(3, 257, increase_by)\n",
    "    efC_range = range(3, 257, increase_by)\n",
    "    post = 1\n",
    "    print(\"Total number of combinations: \", len(ef_range) * len(efC_range) *len(M))\n",
    "    pdict = dict(run=[], M = [], ef = [], efC = [], post = [], accuracy = [], time=[])\n",
    "    n=1\n",
    "    for m in M:\n",
    "        for ef in ef_range:\n",
    "            for efC in efC_range:\n",
    "                rc, tt = test_func(truth=truth_list, bintargets=bintargets, M=m, efC=efC, post=post, ef=ef, threads=4)\n",
    "                n +=1\n",
    "                if rc > 0.9900000000000000:\n",
    "                    pdict['run'].append(n)\n",
    "                    pdict['M'].append(m)\n",
    "                    pdict['ef'].append(ef)\n",
    "                    pdict['efC'].append(efC)\n",
    "                    pdict['post'].append(post)\n",
    "                    pdict['accuracy'].append(rc)\n",
    "                    pdict['time'].append(tt)\n",
    "                    print(n, m, ef, efC, post, rc, tt)\n",
    "    return pdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " aa = sim_nsmlib_para_optimized(10)\n",
    " \n",
    " \n",
    " \n",
    " df = pd.DataFrame.from_dict(aa)\n",
    "\n",
    "\n",
    " df.sort_values(['accuracy', 'time'], ascending=[True, False])\n",
    "\n",
    "\n",
    "\n",
    " df.sort_values(['time'], ascending=[False])\n",
    "\n",
    "\n",
    "\n",
    " df['time'].max() / df['time'].min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
